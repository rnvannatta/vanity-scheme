plan for parallelism

idea: parallel fibers

to fork of an async task, you do (async foo a b c), which yields a future.

behind the scenes async looks like this:

(define (async f . xs)
  (defer-pin f)
  (for-each defer-pin xs)
  (minor-gc)
  (let ((ret (fiber-apply f xs)))
    (set-finalizer! ret (lambda () (unpin f) (for-each unpin xs)))
    ret))

(define (await f)
  (fiber-wait f)
  (finalize! f)
  (fiber-return f))

This requires a 'pinned memory' section of gc. pinned memory is garbage collected by mark and sweep. it's not garbage collected.

pins are added and removed via refcounting. defer-pin waits to add the pin until next gc. can add a weak pin which moves the
object to pinned memory but doesn't refcount

we need to refcount because each fiber is still gcing independently and the originater can drop references to the args

its worth for perf adding an async-copy and async-explicit, where the former doesn't make any pins but copies to the stack, and the latter is syntax which forces the user to declare which happens

one issue with pinning is that if a piece of pinned memory is in the heap, that necessitates a deep gc to copy out all the references to that pinned memory

pinned gc happens when pinning fails or during a major gc.

gc types:

minor : collect stack, account for mutations, and manage pins
heap : collect stack, heap, but not pinned memory
major : collect stack, heap, pinned memory. will compact pinned memory if no fibers
devastating : pause all fibers to collect stack & heap, pause all fibers to compact pinned memory. An emergency gc to handle fragmentation


gc flags for pinned memory:

marked
ref_count

pinned memory with a nonzero ref_count is unmovable except for devastating gcs. pinned memory with a maxed out ref_count is unrecoverable except from devastating gcs.

each fiber has its own pinned memory pool.


fiber storage:
-- fibers consist of: registers, a stack, a heap, and a pinned region
-- registers is negligable
-- stack by abi needs to be 1mb (65535 arguments, half a meg of allocations per gc frame, and a half meg for C calls)
-- heap must fit 2 stacks, ie 2mb, and have two of them
-- pinned region is ???
-- we can defer allocating heaps and pinned region until they're needed
-- we dont actually need 2 heaps except during gc, can return the second heap back to the fiber pool


======================== SO FAR ========================

fibers at a low level have registers, a stack
at a low level a fiber is pushed to the scheduling queue
a fiber worker wakes up and grabs it
when the fiber exits it writes out a return code
the fiber must be waited on to extract the return code and return resources

fibers cannot run on the main thread, the main thread stalls when it yields

per fiber our lithp creates a derivative runtime from the main runtime
the init fiber task launches VStart all the same with the derived runtime

for parallel-for fibers, the calling thread is paused

(exit) in a fiber ends the fiber, returning that value, otherwise the value is
the normal return

Things forbidden during fiber execution:
  binding globals
  setting globals
  setting shared parent memory
  importing

for async fibers... we need to pin memory? mark sweep gc?

16 bit refcount
8 bit bits: what bits do we need? marked, immutable
8 bit pincount
